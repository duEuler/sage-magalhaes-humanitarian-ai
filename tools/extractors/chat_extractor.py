#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Chat Extractor - Classe √∫nica para extra√ß√£o de conversas com IA
Vers√£o refatorada e otimizada do sistema de extra√ß√£o duEuler.com
"""

import json
import re
import os
from datetime import datetime
from typing import List, Dict, Any, Optional

class ChatExtractor:
    """
    Classe principal para extra√ß√£o e an√°lise de conversas com IA.
    Combina todas as funcionalidades em uma √∫nica classe eficiente.
    """
    
    def __init__(self):
        """Inicializa o extrator com padr√µes de identifica√ß√£o."""
        self.ia_patterns = [
            r'O ChatGPT disse:\s*\n(.*?)(?=\n\nVoc√™ disse:|$)',
            r'ChatGPT disse:\s*\n(.*?)(?=\n\nVoc√™ disse:|$)',
            r'IA disse:\s*\n(.*?)(?=\n\nVoc√™ disse:|$)',
            r'Assistant:\s*\n(.*?)(?=\n\nUser:|$)',
            r'AI:\s*\n(.*?)(?=\n\nUser:|$)'
        ]
        
        self.user_patterns = [
            r'Voc√™ disse:\s*\n(.*?)(?=\n\nO ChatGPT disse:|$)',
            r'Voc√™ disse:\s*\n(.*?)(?=\n\nChatGPT disse:|$)',
            r'Voc√™ disse:\s*\n(.*?)(?=\n\nIA disse:|$)',
            r'User:\s*\n(.*?)(?=\n\nAssistant:|$)',
            r'User:\s*\n(.*?)(?=\n\nAI:|$)'
        ]
    
    def extract_from_file(self, file_path: str) -> List[Dict[str, Any]]:
        """
        Extrai mensagens de um arquivo de conversa mantendo a ordem cronol√≥gica.
        
        Args:
            file_path: Caminho para o arquivo
            
        Returns:
            Lista de mensagens estruturadas em ordem cronol√≥gica
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            
            messages = []
            message_id = 1
            
            # Dividir o conte√∫do em se√ß√µes baseadas nos marcadores
            sections = []
            
            # Padr√£o para encontrar todas as se√ß√µes
            pattern = r'(?:O ChatGPT disse:\s*\n|Voc√™ disse:\s*\n)(.*?)(?=\n\n(?:O ChatGPT disse:|Voc√™ disse:)|$)'
            matches = re.findall(pattern, content, re.DOTALL)
            
            # Encontrar os marcadores para determinar a ordem
            markers = re.findall(r'(O ChatGPT disse:|Voc√™ disse:)', content)
            
            # Verificar se h√° uma primeira mensagem do usu√°rio (antes de "O ChatGPT disse:")
            first_part = content.split('O ChatGPT disse:')[0].strip()
            if first_part and not first_part.startswith('Voc√™ disse:'):
                # Adicionar primeira mensagem do usu√°rio
                messages.append({
                    'id': message_id,
                    'sender': 'usuario',
                    'content': first_part,
                    'timestamp': None,
                    'type': 'text',
                    'word_count': len(first_part.split())
                })
                message_id += 1
            
            # Processar as mensagens em ordem cronol√≥gica
            current_pos = 0
            for i, marker in enumerate(markers):
                if marker == 'O ChatGPT disse:':
                    # Encontrar o conte√∫do da IA
                    start = content.find('O ChatGPT disse:', current_pos)
                    end = content.find('Voc√™ disse:', start)
                    if end == -1:
                        end = len(content)
                    
                    ia_content = content[start + len('O ChatGPT disse:'):end].strip()
                    if ia_content:
                        messages.append({
                            'id': message_id,
                            'sender': 'ia',
                            'content': ia_content,
                            'timestamp': None,
                            'type': 'text',
                            'word_count': len(ia_content.split())
                        })
                        message_id += 1
                    
                    current_pos = end
                
                elif marker == 'Voc√™ disse:':
                    # Encontrar o conte√∫do do usu√°rio
                    start = content.find('Voc√™ disse:', current_pos)
                    end = content.find('O ChatGPT disse:', start)
                    if end == -1:
                        end = len(content)
                    
                    user_content = content[start + len('Voc√™ disse:'):end].strip()
                    if user_content:
                        messages.append({
                            'id': message_id,
                            'sender': 'usuario',
                            'content': user_content,
                            'timestamp': None,
                            'type': 'text',
                            'word_count': len(user_content.split())
                        })
                        message_id += 1
                    
                    current_pos = end
            
            return messages
            
        except FileNotFoundError:
            print(f"‚ùå Arquivo n√£o encontrado: {file_path}")
            return []
        except Exception as e:
            print(f"‚ùå Erro ao processar arquivo: {e}")
            return []
    
    def analyze_conversation(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Analisa estat√≠sticas da conversa.
        
        Args:
            messages: Lista de mensagens
            
        Returns:
            Dicion√°rio com estat√≠sticas
        """
        if not messages:
            return {}
        
        ia_messages = [m for m in messages if m['sender'] == 'ia']
        user_messages = [m for m in messages if m['sender'] == 'usuario']
        
        total_words_ia = sum(m.get('word_count', 0) for m in ia_messages)
        total_words_user = sum(m.get('word_count', 0) for m in user_messages)
        
        avg_words_ia = total_words_ia / len(ia_messages) if ia_messages else 0
        avg_words_user = total_words_user / len(user_messages) if user_messages else 0
        
        return {
            'total_messages': len(messages),
            'ia_messages': len(ia_messages),
            'user_messages': len(user_messages),
            'total_words_ia': total_words_ia,
            'total_words_user': total_words_user,
            'avg_words_ia': round(avg_words_ia, 2),
            'avg_words_user': round(avg_words_user, 2),
            'conversation_ratio': f"{len(ia_messages)}:{len(user_messages)}",
            'first_sender': messages[0]['sender'] if messages else None,
            'last_sender': messages[-1]['sender'] if messages else None
        }
    
    def save_json(self, messages: List[Dict[str, Any]], output_file: str, 
                  source_file: str, include_analysis: bool = True) -> bool:
        """
        Salva as mensagens em formato JSON.
        
        Args:
            messages: Lista de mensagens
            output_file: Arquivo de sa√≠da
            source_file: Arquivo de origem
            include_analysis: Se deve incluir an√°lise estat√≠stica
            
        Returns:
            True se salvou com sucesso
        """
        try:
            chat_data = {
                'metadata': {
                    'extracted_at': datetime.now().isoformat(),
                    'source_file': source_file,
                    'extractor_version': '3.0',
                    'total_messages': len(messages)
                },
                'conversation': messages
            }
            
            if include_analysis:
                chat_data['analysis'] = self.analyze_conversation(messages)
            
            with open(output_file, 'w', encoding='utf-8') as file:
                json.dump(chat_data, file, ensure_ascii=False, indent=2)
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erro ao salvar JSON: {e}")
            return False
    
    def process_single_file(self, input_file: str, output_file: Optional[str] = None, 
                           include_analysis: bool = True, show_summary: bool = True) -> bool:
        """
        Processa um arquivo √∫nico de conversa.
        
        Args:
            input_file: Arquivo de entrada
            output_file: Arquivo de sa√≠da (opcional)
            include_analysis: Se deve incluir an√°lise
            show_summary: Se deve mostrar resumo
            
        Returns:
            True se processou com sucesso
        """
        if not os.path.exists(input_file):
            print(f"‚ùå Arquivo n√£o encontrado: {input_file}")
            return False
        
        # Gerar nome do arquivo de sa√≠da se n√£o fornecido
        if not output_file:
            base_name = os.path.splitext(os.path.basename(input_file))[0]
            output_file = f"{base_name}_conversa.json"
        
        print(f"üìÇ Processando: {input_file}")
        
        # Extrair mensagens
        messages = self.extract_from_file(input_file)
        
        if not messages:
            return False
        
        # Mostrar resumo se solicitado
        if show_summary:
            self.print_summary(messages, input_file)
        
        # Salvar JSON
        success = self.save_json(messages, output_file, input_file, include_analysis)
        
        if success:
            print(f"‚úÖ JSON salvo: {output_file}")
            return True
        
        print(f"‚ùå Falha ao salvar: {output_file}")
        return False
    
    def process_directory(self, input_dir: str, output_dir: str = "extracted_conversations") -> Dict[str, Any]:
        """
        Processa todos os arquivos .txt em um diret√≥rio.
        
        Args:
            input_dir: Diret√≥rio de entrada
            output_dir: Diret√≥rio de sa√≠da
            
        Returns:
            Dicion√°rio com estat√≠sticas do processamento
        """
        # Criar diret√≥rio de sa√≠da se n√£o existir
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"üìÅ Diret√≥rio criado: {output_dir}")
        
        # Encontrar arquivos .txt
        txt_files = [f for f in os.listdir(input_dir) if f.endswith('.txt')]
        
        if not txt_files:
            print(f"‚ùå Nenhum arquivo .txt encontrado em: {input_dir}")
            return {}
        
        print(f"üîµ Processando {len(txt_files)} arquivos...")
        
        results = {
            'total_files': len(txt_files),
            'processed_files': 0,
            'total_messages': 0,
            'files': []
        }
        
        # Processar cada arquivo
        for txt_file in txt_files:
            input_path = os.path.join(input_dir, txt_file)
            base_name = os.path.splitext(txt_file)[0]
            output_file = os.path.join(output_dir, f"{base_name}_conversa.json")
            
            messages = self.extract_from_file(input_path)
            
            if messages:
                success = self.save_json(messages, output_file, input_path, include_analysis=True)
                
                if success:
                    results['processed_files'] += 1
                    results['total_messages'] += len(messages)
                    
                    analysis = self.analyze_conversation(messages)
                    results['files'].append({
                        'filename': txt_file,
                        'output_file': f"{base_name}_conversa.json",
                        'messages': len(messages),
                        'analysis': analysis
                    })
        
        return results
    
    def print_summary(self, messages: List[Dict[str, Any]], source_file: str) -> None:
        """
        Imprime resumo da extra√ß√£o.
        
        Args:
            messages: Lista de mensagens
            source_file: Arquivo de origem
        """
        if not messages:
            print("‚ùå Nenhuma mensagem extra√≠da.")
            return
        
        analysis = self.analyze_conversation(messages)
        
        print(f"\nüìä RESUMO:")
        print(f"   üìÇ Arquivo: {source_file}")
        print(f"   üìù Mensagens: {analysis['total_messages']}")
        print(f"   ü§ñ IA: {analysis['ia_messages']}")
        print(f"   üë§ Usu√°rio: {analysis['user_messages']}")
        print(f"   üìä Propor√ß√£o: {analysis['conversation_ratio']}")
        print(f"   üìà Palavras: {analysis['total_words_ia'] + analysis['total_words_user']}")

def main():
    """Fun√ß√£o principal para uso direto do script."""
    print("üîµ Chat Extractor - duEuler.com")
    print("=" * 50)
    
    extractor = ChatExtractor()
    
    # Processar arquivo padr√£o
    input_file = "datasets/conversations/backup/1 - nascimento.txt"
    output_file = "conversa_duEuler.json"
    
    if extractor.process_single_file(input_file, output_file):
        print(f"\nüéâ Conversa extra√≠da com sucesso!")
        print(f"üìÑ Arquivo: {output_file}")
    else:
        print("‚ùå Falha no processamento.")

if __name__ == "__main__":
    main() 